# labcuda
CUDA, python3, PyCUDA, matrix multiplication
Работа выполнялась с помощью: python3, CUDA, Google Colab
- Основная особенность PyCUDA позволяет создавать ядро на C++, а затем запускать его на GPU.
- Одним из самых быстрых способов умножения матрицы является использование numpy.dot(), поскольку его реализация построена на C
- В этой работе я сравнил время работы двух способов на gpu с numpy.dot() и с ядром C++ в PyCUDA на матрицах разного размера.

Результаты:
  |  N  | CPU time, ms | GPU time, ms | Speedup|
  |:---:|:------------:|:------------:|:------:|
  | 128 |        0.122 |        0.422 |    0.29|
  | 256 |        0.613 |        0.615 |    1.00|
  | 512 |        4.498 |        2.164 |    2.08|
  |1024 |       33.361 |        9.894 |    3.37|
  |2048 |      258.712 |       62.114 |    4.17|

Заключение:
  Как можно увидеть, на матрицах малых размеров CPU вычисляет лучше GPU в несколько раз, но с ростом размера матрицы, GPU показывает значительный рост, по сравнению с CPU. Это означает, что для перемножения матриц больших размеров наиболее целесообразно использовать GPU, а не CPU.
