# labcuda
CUDA, python3, PyCUDA, matrix multiplication
Работа выполнялась с помощью: python3, CUDA, Google Colab
- Основная особенность PyCUDA позволяет создавать ядро на C++, а затем запускать его на GPU.
- Одним из самых быстрых способов умножения матрицы является использование numpy.dot(), поскольку его реализация построена на C
- В этой работе я сравнил время работы двух способов на gpu с numpy.dot() и с ядром C++ в PyCUDA на матрицах разного размера.

Результаты:
  |  N  | CPU time, ms | GPU time, ms | Speedup|
  |:---:|:------------:|:------------:|:------:|
  | 128 |        0.609 |        0.993 |    0.61|
  | 256 |        0.636 |        1.266 |    0.50|
  | 512 |        4.559 |        6.229 |    0.74|
  |1024 |       33.211 |        36.059|    0.92|
  |2048 |      248.920 |       189.160|    1.32|

Заключение:
  Как можно увидеть, на матрицах малых размеров CPU вычисляет лучше GPU в несколько раз, но с ростом размера матрицы, GPU показывает значительный рост, по сравнению с CPU. Это означает, что для перемножения матриц больших размеров наиболее целесообразно использовать GPU, а не CPU.
