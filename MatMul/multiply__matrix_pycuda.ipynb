{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiply__matrix_pycuda.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iyGT81u4WzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5356a8-49da-4918-8f3b-381fb023fe77"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2021.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 1.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "  Downloading pytools-2021.2.8.tar.gz (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=628011 sha256=aee1151588b17a5f7d83c5c4b32305b833f157c00b55f3f8c3858febd950a272\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/ef/49/dc6a5feb8d980b37c83d465ecab24949a6aa19458522a9e001\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2021.2.8-py2.py3-none-any.whl size=60725 sha256=97fbe03e9972c74859d7816eb476032d68571b2bdc3c79bb0e67f16cf8f15f1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/2d/ef/0127a17bafa44971f11d05d0e38d7947144cf9e33313bf12a7\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.1.5 pycuda-2021.1 pytools-2021.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH7XYQWsbqnW"
      },
      "source": [
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "from pycuda import compiler, gpuarray, tools\n",
        "import pycuda.driver as drv\n",
        "import pycuda.autoinit"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rKUjbx4Gie1"
      },
      "source": [
        "MATRIX_SIZES = [128, 256, 512, 1024,2048]\n",
        "BLOCK_SIZE = 16"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsDUH9skFOgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6bc3d2-bfd6-4030-906d-a644cdd44bfd"
      },
      "source": [
        "kernel_code_template = \"\"\"\n",
        "__global__ void matrix_multiply(int matrixsize,float *a, float *b, float *c)\n",
        "{\n",
        "    // 2D Thread ID \n",
        "    int tx = blockDim.x*blockIdx.x + threadIdx.x; // Compute column index\n",
        "    int ty = blockDim.y*blockIdx.y + threadIdx.y; // Compute row index\n",
        "    // Each thread loads one row of M and one column of N, \n",
        "    //   to produce one element of P.\n",
        "    if((ty <matrixsize) && (tx < matrixsize))\n",
        "    {\n",
        "    // Pvalue is used to store the element of the matrix\n",
        "    // that is computed by the thread\n",
        "    float Pvalue = 0;\n",
        "    for(int k=0; k<matrixsize; ++k)\n",
        "    {\n",
        "    float Aelement = a[ty*matrixsize +k];\n",
        "    float Belement = b[k*matrixsize +tx];\n",
        "    Pvalue += Aelement * Belement;\n",
        "    }\n",
        "    c[ty * matrixsize + tx] = Pvalue;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# compile the kernel code\n",
        "mod = compiler.SourceModule(kernel_code_template)\n",
        "\n",
        "# get the kernel function from the compiled module\n",
        "matrix_multiply = mod.get_function(\"matrix_multiply\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weTRG0-CGsh9"
      },
      "source": [
        "def multiply_with_cpu(a, b):\n",
        "  return a.dot(b)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpPd_mWyHXpN"
      },
      "source": [
        "def multiply_with_gpu(a, b, MATRIX_SIZE):\n",
        "  # transfer host (CPU) memory to device (GPU) memory\n",
        "  a_gpu = gpuarray.to_gpu(a)\n",
        "  b_gpu = gpuarray.to_gpu(b)\n",
        "\n",
        "  # create empty gpu array for the result (C = A * B)\n",
        "  c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "  # set grid size\n",
        "  #if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    #  grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "  #else:\n",
        "  grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "\n",
        "  # call the kernel on the card\n",
        "  matrix_multiply(np.uint32(MATRIX_SIZE),\n",
        "    # inputs\n",
        "    a_gpu, b_gpu,\n",
        "    # output\n",
        "    c_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1),\n",
        "    )\n",
        "  return c_gpu  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8uz60EaNgdk"
      },
      "source": [
        "def calculate(a, b, MATRIX_SIZE):\n",
        "      start_cpu = timer()\n",
        "      c_cpu = multiply_with_cpu(a, b)\n",
        "      cpu_multiply_time = timer() - start_cpu\n",
        "\n",
        "      start_gpu = timer()\n",
        "      c_gpu = multiply_with_gpu(a, b, MATRIX_SIZE)\n",
        "      gpu_multiply_time = timer() - start_gpu\n",
        "  \n",
        "      return cpu_multiply_time * 1000, gpu_multiply_time * 1000, np.allclose(c_cpu, c_gpu.get())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-YZhk-_PZ7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4101406c-5926-46d6-e603-7546fbdcc048"
      },
      "source": [
        "count = 15\n",
        "\n",
        "print(\" N \\t CPU time \\t GPU time \\t Speedup\")\n",
        "\n",
        "for size in MATRIX_SIZES:\n",
        "  cpu_time = 0\n",
        "  gpu_time = 0\n",
        "\n",
        "  for i in range(count):\n",
        "    a = np.random.rand(size, size).astype(np.float32)\n",
        "    b = np.random.rand(size, size).astype(np.float32)\n",
        "\n",
        "    current_cpu_time, current_gpu_time, err = calculate (a, b, size)\n",
        "    cpu_time += current_cpu_time\n",
        "    gpu_time += current_gpu_time\n",
        "\n",
        "  if err is False:\n",
        "      print(\"N = {:d}: results not equals\".format(size))\n",
        "\n",
        "  print(\"{:4d} \\t {:7.3f} \\t {:7.3f} \\t {:7.2f}\".format(size, cpu_time / count, gpu_time / count, cpu_time / gpu_time))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " N \t CPU time \t GPU time \t Speedup\n",
            " 128 \t   0.609 \t   0.993 \t    0.61\n",
            " 256 \t   0.636 \t   1.266 \t    0.50\n",
            " 512 \t   4.599 \t   6.229 \t    0.74\n",
            "1024 \t  33.211 \t  36.059 \t    0.92\n",
            "2048 \t 248.920 \t 189.160 \t    1.32\n"
          ]
        }
      ]
    }
  ]
}